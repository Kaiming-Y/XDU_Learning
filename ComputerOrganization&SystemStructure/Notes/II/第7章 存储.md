# 第7章 存储

## 7.3 高速缓冲存储器 Cache

### 存储系统的多层次结构

- ***cache - 主存 - 辅存*** 三级存储体系：三级存储层次

- ***主存 - 辅存*** 存储层次：

  - 大容量、低成本

  - 软硬件结合完成

- ***cache - 主存*** 存储层次：

  - 高速度、低成本

  - 纯硬件完成

<u>解决存储系统三个指标：**容量**、**速度**、**价格/位**的矛盾</u>  

### 7.3.1 cache 工作原理

<u>主要依据： **程序的局部性原理**</u>

两种可预测的主存访问性质：

- ***时间局部性*** ：某位置若被访问，则 <u>近期内</u> 很可能又被访问。  
- ***空间局部性*** ：某位置若被访问，则 <u>临近的位置</u> 也可能被访问  

#### 1. 概述

##### a. cache的位置

![1](img/7/1.png)

![2](img/7/2.png)

##### b. cache的构成

![3](img/7/3.png)

##### c. cache的工作过程

![4](img/7/4.png)

#### 2. 地址映射

##### 块

- 块号
- 块内地址

![5](img/7/5.png)

地址字段划分示意图：

![6](img/7/6.png)

##### 命中/不命中

- 若在相联存储表中检索到读写的信息就在高速cache中，则通过相联存储表将地址转换为cache地址，从中读出信息。这种情况称为“命中”。
- 若在相联存储表中未能检索到要读的信息，则称为“未命中”。 

#### 2. 地址映像、地址变换

> cache 和主存分成容量相等的块

#####  a. 全相联映射方式

- 法则：==主存的任何一块可以装入到cache的任何一块中。==
- 特点：主存块装入位置无限制，仅当Cache全部装满后才会出现冲突，即块冲突概率最低，但是相联存储器的容量最大，变换机构复杂。  

![7](img/7/7.png)

> 存放主存块号的相联存储器应有cache块数个单元
>
> 相联存储器中存放主存地址块号

##### b. 直接映射方式

- 法则：==主存各区中块号相同的块只能装入与cache中相同的块号==
- 特点：主存块装入位置限制，主存不同区的相同块将无法同时出现在Cache中，块冲突概率最高，但是相联存储器的容量最小，变换简单，命中时可直接由主存地址中提取到Cache地址。  

![8](img/7/8.png)

> 相联存储器中存放主存地址主存区号

##### c. 组相联映射方式

- 基本思想：将cache先分组，组内再分块；主存先以cache的总容量**分区**，区内按cache的方法**分组**，组内再**分块**。
- 规则：组间直接、组内全相联
- 特点：是前两种方式的折中，即块冲突概率和变换复杂度均处于中间位置。  

![9](img/7/9.png)

> 相联存储器中存放主存地址中主存区号和块号

**地址变换表(相联存储器) **还在每一个存储单元设定：

1. 设置1位有效位
   - 规定该位为1时，该块有效；
   - 该位为0时，该块无效。
2. 在数据Cache的相联存储器中，对应着Cache的一块设置1位修改位
   - 当在该块在使用中数据被修改时，用该位标志。  
3. 为替换方便，可设置计数器  

### 7.3.2 替换算法

若 Cache未命中，而 Cache已装满，则需替换Cache中的块。

#### a. 随机替换算法 RAND

这种算法是用随机函数发生器产生需替换的块号，将其替换。

> 这种方法没有考虑信息的历史及使用情况，故其命中率比较低。目前已不再使用。  

#### b. 先进先出算法 FIFO

该算法是将最先装入Cache的那一块替换出去。  

> 这种方法只考虑信息的历史情况而没有考虑其使用情况，也许最先装入的那一块正在频繁使用。因此，该算法也有一定局限性，命中率也不是很高。

#### c. 近期最少使用算法 LRU

对每块设置一个**计数器**，某块每命中一次，就将其计数器清0而其他块的计数器加1，记录Cache中各块的使用情况。  

*<u>当需要替换时，便将计数值最大的块替换出去。</u>*

> 由于Cache的工作是建立在程序执行及数据访问的 **局部性原理**。因此，该算法较前两种算法的命中率要高一些。  

#### d. 最不经常使用算法 LFU

对每块设置一个计数器，且开始调入时计数为0。每被访问一次，被访问块的计数器加1。

*<u>当需要替换时，便将计数值最小的块替换出去，同时将所有各块的计数器清 0。</u>*  

> 将计数周期限定在两次替换的时间间隔内。不能完全反映近期的访问情况。

#### e. 最优替换算法 OTP

要实现这种算法程序需执行两次。  

执行第一遍时，记录各块地址的使用情况。根据第一遍的记录就能找出需要替换出去的该是哪块。有了先验的替换信息，在第二次执行时一定能将命中率达到最高。  

> 非实用算法，仅作为算法评价的基准  

### 7.3.3 主存-cache 内容的一致性

#### 写回法

- 当CPU写Cache命中时，只将数据写入Cache而不立即写入主存。<u>只有当被CPU写入修改的块被替换出去时才写回到主存中。</u>

  *这种方法减少了访问主存的次数,但是存在不一致性的隐患。*

- 如果CPU写Cache未命中，则写修改是将相应主存块调入Cache之后，在Cache中进行。<u>对主存的修改仍留待该块替换出去时进行。</u>

  *实现这种方法时，每个 cache 行必须配置一个修改位，以反映此行是否被CPU修改过。*  

#### 全写法（写直达）

- 当CPU写Cache命中时，<u>在将数据写入修改Cache的同时写入修改主存</u>，较好地保证了主存与Cache内容的一致性。  
  - 当写cache命中时， cache与主存同时发生写修改，因而较好地维护了cache与主存的内容的一致性。
  - Cache中每块无需设置一个修改位以及相应的判断逻辑。缺点是Cache对CPU向主存的写操作无高速缓冲功能，降低了Cache的功效。  
- 当写cache未命中时，<u>直接向主存进行写入。</u>这时可以采用两种方式进行处理：  
  - WTWA：（ Write Through With Write Allocate）取主存块到Cache并为其分配一个行位置；  
  - WTNWA：（ Write Through With No Write Allocate）不取主存块到Cache。  

![10](img/7/10.png)

### 7.3.4 cache 的性能分析

#### a. Cache的命中率 (Hit Rate)

在一个程序执行期间，设 $N_c$ 表示cache完成存取的总次数， $N_m$ 表示主存完成存取的总次数， $H$ 定义为命中率，则有：

$H = \frac{N_c}{N_c + N_m}$

#### b. 非命中率 (Miss Rate)

cache 非命中

$1 - H$

![13](img/7/13.png)

> ![16](img/7/16.png)

#### c. 加速比

![14](img/7/14.png)

**访存时间的有关说明**：<u>与Cache的访问和控制机制有关</u>

![15](img/7/15.png)

#### d. 成本

![17](img/7/17.png)

- 尽管cache的价格比主存高，但是当其容量很小时，存储器的平均价格 C 接近于主存的价格。
- 由于设置了cache使CPU的访存速度接近cache的速度，而使存储器的成本接近于主存的价格。

#### cache 性能分析：miss的4C类型

- compulsory 必然

  冷启动、过程转移、首次引用等不可避免的miss

- capacity 容量

  容量不够造成的

- conflict 冲突

  cache块冲突

  - 方案1：增加容量
  - 方案2：提升相联度

- coherence 一致性

  其他操作带来的结构相关（I/O操作等）

> ***capacity*** 和 ***conflict miss*** 随 ***cache容量*** 提升而降低

#### cache 性能分析与优化

##### 1 命中率与cache容量的关系

![19](img/7/19.png)

##### 2 命中率与块大小的关系

![20](img/7/20.png)

![21](img/7/21.png)

##### 3 不命中率与多路相联的关系

![18](img/7/18.png)

- 提升组相联级别
- 级别也不要太高：级别提升的边际效率在下降
  - 相联比较复杂
  - 相联存取复杂 -> 提高 T~c~ 时间

##### 4 两级 cache

![22](img/7/22.png)

![23](img/7/23.png)

![24](img/7/24.png)

##### 5 拆分出 <u>指令</u> / <u>数据</u> 独立cache

![25](img/7/25.png)

##### 6 代码层面优化

![26](img/7/26.png)

![27](img/7/27.png)

![28](img/7/28.png)

![29](img/7/29.png)

## 7.4 虚拟存储器 VM

### 7.4.1 概念

- 虚拟存储技术是在主存与辅存之间，增加软件及必要的硬件，使主、辅存之间的信息交换，程序的再定位，地址的转换都能自动进行，使两者形成一个有机的整体。<u>以透明的方式给用户提供了一个比实际主存空间大得多的程序地址空间。</u>
- 由于程序员可以用到的空间远远大于主存的实际空间，但实际并不存在这么大的主存，故称“虚拟存储器”（Virtual Memory ）简称 VM 。

![11](img/7/11.png)

- 虚拟存储器是由价格比较贵、容量不太大、速度相对比较高的 **主存储器** 和价格很低、容量非常大、速度慢的 **外部（辅助）存储器**，在 **操作系统** 及 **辅助硬件** 的管理下，构成了像一个单一的、可直接访问的超大容量的主存储器。
- 解决主存容量与价格的矛盾，使速度接近主存速度而容量和价格又接近外存

![12](img/7/12.png)

### <u>Cache-主存</u> 和 <u>主存-辅存</u> 两个存储层次的比较

#### 相同点

- 主存-外存层次和cache-主存层次用的**地址变换映射方法**和**替换策略的思想**是相同的，都基于程序 ***局部性原理*** 。
- 遵循的原则都是：
  - 把程序中最近<u>常用的部分驻留在高速的存储器中</u>。
  - 一旦这部分变得不常用了，把它们送回到低速的存储器中。
  - 这种换入换出是由<u>硬件或操作系统完成的</u>，对用户是透明的。
  - <u>力图使存储系统的性能接近高速存储器，价格接近低速存储器</u>。

#### 区别

- **目的不尽相同。**
  - cache主要解决主存与CPU的速度差异问题；
  - 辅存主要是解决存储容量的问题。
- **数据通路不同。**
  - CPU与cache和主存之间均有直接访问通路,cache不命中时可直接访问主存;
  - 辅存与CPU之间不存在直接的数据通路,当主存不命中时只能通过调页解决,CPU最终还是要访问主存。
- **透明性不同。**
  - cache的管理完全由<u>硬件完成</u>,对系统程序和应用程序均透明；
  - 虚存管理由<u>软件(操作系统)和硬件共同完成</u>,对系统程序不透明,对应用程序透明(段式和段页式管理对应用程序“半透明” ).
- **未命中时的损失不同。**
  - 由于主存的存取时间是 cache 的5~10倍；
  - 辅存的存取时间通常是主存的上千倍,故虚存未命中时系统的性能损失远大于 cache未命中时的损失。